Previous studies address interoperability and composability of parallel programming models and libraries 
from different aspect and for different programming models. 
Tian et al.~\cite{tian2003compiler} explored interoperability between OpenMP threads and system threads in the Intel OpenMP compiler.
For ease of use for programmers, they decided not to share thread identifiers between system threads and their OpenMP parent
and not to share {\sf threadprivate} variables among system threads.
%Also, a forked system thread calling \lstinline{omp_in_parallel()} would return false, even if it is created by an OpenMP thread. 
Callisto~\cite{Callisto:Harris:2014:CCP:2592798.2592807} and
Lithe~\cite{Lithe:Pan:2009:LEE:1855591.1855602} 
address the interoperability challenge 
through the design of a low-level software layer for common 
resource management underneath multiple parallel runtime systems, such as OpenMP and TBB. % of programming models. 
%They however do not address the algorithm conflicts of different runtime systems. 
In order to compose multiple simultaneously executing parallel applications, Hugo et al.~\cite{hugo2014composing} extends the starPU runtime system to allow confined execution environments (called scheduling contexts) which can be used to partition computing resources. 
A hypervisor is used to automatically expand or shrink contexts based on runtime resource utilization feedback. 

The MPC (Multi-Processor Computing) framework~\cite{perache2008mpc} is a unified parallel runtime designed for clusters of large NUMA nodes. 
Through process virtualization and thread-based MPI implementation, MPC enables efficient mixing of MPI, OpenMP, and PThreads. 
The MPI endpoints~\cite{Dinan:mpiendpoint_eurompi13}
proposal to the MPI standard relaxes the one-to-one relationship between processes and ranks.
It allows registering a thread in an MPI
process as a MPI communicator rank that is able to independently participate
in message passing operations. There are also efforts of integrating MPI calls as
tasks in a intra-node workstealing runtime~\cite{hcmpi:ipdps13}.

To enable interoperability among distributed HPC programming models, Epperly et al.~\cite{epperly2011composite} proposed a mixed-language environment supporting arbitrary combination of software written in PGAS languages (Co-Array Fortran, UPC, and Titanium) and HPCS languages (Chapel, X10, and Fortress). 
They designed the Scientific Interface Definition Language (SIDL) and Babel Intermediate Object Representation (IOR) as a language-independent object-oriented programming model and type system
to allow software components to share complicated data structures across various languages. 
