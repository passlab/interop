
%Most implementations of the parallel programming APIs rely on system 
%native threading (PThreads or Windows Native threads) mechanisms to acquires system resources. 
%Each implementation of the same or different APIs has its own mechanism and algorithms for managing
%CPU resources. 
%OpenMP has been evolved to be a unified programming model for 
%parallel and heterogeneous computing nodes by including fork-join execution model, 
%data parallelism (worksharing), task parallelism, offloading execution model, etc.. 
%The runtime systems are becoming more complicated than before to support those language features.
A typical OpenMP runtime maintains 
an internal thread pool to keep track of the native threads created by the runtime, 
%even they are not doing any OpenMP operation, e.g.
even during the sequential execution of the program. 
In the OpenMP's fork-join execution model, a native thread in the thread pool 
is summoned to participate in an OpenMP team for computation upon the fork of a {\sf parallel} region. 
The native thread returns back to the thread pool when the {\sf parallel} 
region is finished at the join barrier. While in the 
thread pool, a native thread blocks in a fork barrier. 
OpenMP runtime may also
%Instead of moving the blocking thread to the thread pool, 
maintains internal hot teams that keep threads actively waiting for the upcoming {\sf parallel} regions. 
%in which threads are busy-waiting for work even if the program is in the sequential stage. 
So an OpenMP program could consumes cycles of multiple CPU cores even if it is in sequential execution stage.

It is also often that an OpenMP program explicitly create native threads, e.g. PThreads, and each native thread has
its own OpenMP {\sf parallel} region. 
In such hybrid threading model (user-level native thread and OpenMP thread), 
a runtime maintains internal descendant hierarchies for the native threads created by users and
those by the OpenMP runtime. Borrowing the term from Intel OpenMP runtime, we refer to 
the native threads created by users as root threads. 
Based on the most recent OpenMP standard, a root thread forms a contention group and we thus 
consider all the descendant threads are members of the group. 


The oversubscription challenge is then concerned with how 
to coordinate the CPU resource sharing between two or more contention groups, and between multiple 
runtime instances, which could be of the same or different runtime libraries. 
Our solutions for addressing it provide users APIs for 
dynamically setting the waiting policy of the blocking thread to minimize 
the consumption of CPU cycles when idling. 
%so threadsthat do not do useful work consume minimum CPU cycles. 


\subsection{Definition of the {\sf ACTIVE} and {\sf PASSIVE} Wait Policies}
Our proposal defines more specifically 
the {\sf ACTIVE} and {\sf PASSIVE} policies and also extends each to include multiple policies that dictate more
specifically the exact behavior of the waiting thread. 
When a thread is waiting in {\sf ACTIVE} state, it should not initiate calls to
relinquish the CPU, though technically the OS kernel or hardware may switch it out of the core it occupies. 
When in {\sf PASSIVE} state, a thread initiates yielding or suspension operation to give up the CPU core. 
The extensions of each of the policies are summarized in Table~\ref{table:implement_wait} and detailed description
 are as follows. % the table. 
\begin{table}[ht]
	\centering
\resizebox{12.5cm}{!}{
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{2}{|c|}{\textbf{Wait Policy}} & \textbf{Description} & \textbf{Pseudo Code} \\
\hline
\multirow{2}[4]{*}{{\sf ACTIVE}} & {\sf SPIN\_BUSY} & Busy wait in user level & while (!finished()) ; \\
\cline{2-4}      & {\sf SPIN\_PAUSE} & Busy wait while pausing CPU & while (!finished()) cpu\_pause(); \\
\hline
\multirow{3}[6]{*}{{\sf PASSIVE}} & {\sf SPIN\_YIELD} & Busy wait with yield & while (!finished()) sched\_yield(); \\
\cline{2-4}      & {\sf SUSPEND} & Thread sleeps. Others wake it up. & mutex\_wait(); mutex\_wake(); \\
\cline{2-4}      & {\sf TERMINATE} & Thread terminates. &  pthread\_exit();\\
\hline
\end{tabular}%
}
\label{table:implement_wait}
\caption{Wait Policies}
\end{table}

%The blocking mechaims could be  
%either busy-waiting which occupies a CPU core, or in the kernel
%scheduling queue after a yield system call (e.g. {\em sched\_yield} in Linux), or could be put to sleep. 
%thread could be in one of the following states while not participating in OpenMP computations.  
{\sf {\bf ACTIVE SPIN\_BUSY}}: The blocking thread waits in a loop purely in user space. 
%		It is released from the barrier to participate in a team for computation by the runtime. 
		It consumes CPU cycles and memory bandwidth while iteratively checking
		the condition for being released. This policy allows the fastest response time when a thread is
		released from the barrier. 

	{\bf ACTIVE SPIN\_PAUSE}: The blocking thread waits using a loop and also pauses the CPU core in 
	each loop iteration. The pause operation introduces a slight delay in the loop, reducing the amount 
	of instructions fed into the pipeline as well as the energy consumption. This policy also allows 
	for very fast response time but consuming much less amount of CPU cycles 
	and memory bandwidth than the {\sf SPIN\_BUSY} policy.

	{\bf PASSIVE SPIN\_YIELD}:  The blocking thread waits using a loop and 
	relinquishes the CPU in each iteration by kernel system call (e.g. {\em sched\_yield}). CPU yielding causes
	the thread to be moved to the end of the kernel scheduling queue for its static priority. A thread in this 
		stage can only be released to the OpenMP runtime by the kernel. Kernel context switch is involved
		in each loop iteration, thus having higher overhead than the two {\sf ACTIVE} policies. 
		This policy provides average response time, but allows kernel to schedule other tasks to the same
		CPU core while the thread yields. 

	{\bf PASSIVE SUSPEND}: The thread is suspended when waiting in the barrier call. A suspended thread can only
	be resumed by other threads, being timed out, or upon some hardware state change~\footnote{
                    On Intel platforms, this can be implemented using {\em monitor-mwait}.
                    Blue Gene/Q supported a ``wake-up unit'' for fast thread resumption.
                     Other processors may have similar features.}. A suspended thread, also known as sleeping,  
		     does not consume CPU cycles. 
		     However the operations of suspending or resuming a thread are costly. 
		     Thus this approach has the longest response time and 
		     the kernel can completely allocate other tasks to the CPU 
		     core previously used by the suspended thread. % that is suspended now.

       {\bf PASSIVE TERMINATE}: The thread will be terminated instead of waiting in the runtime. Though not technically accurate as
       a ``waiting" policy, it is categorized as the {\sf PASSIVE} policy because of the same effect of it as the {\sf PASSIVE SUSPEND} policy. 
       By introducing this policy, 
       we give users an option to return completely the CPU cores to the system, though the future request of thread requires 
       recreating the thread. The termination and recreation of a thread cost more than suspending and resuming a thread.  

\subsection{Proposed Runtime Routines} 
%This interoperability proposal is an effort from OpenMP interoperability language subcommittee for addressing
%the oversubscription challenges of OpenMP programs when being executed with other threading library. 
Our extensions to OpenMP are runtime routines that can expose 
certain functionalities of the runtime system for users to 
intrusively adjust the behavior of the waiting threads.  
%These routines  API for providing more information or control to users 
%for the threads in the runtime, 
They also include routines for the runtime to contribute OpenMP threads for another parallel runtime, without
the need to create a {\sf parallel} region. The specifications are included in the follow list. 
%Parallel programming models such as 
%The proposal introduces the following definition of data types and runtime routines. 

\lstset{basicstyle=\sffamily\footnotesize,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

typedef enum omp_wait_policy {
  OMP_SPIN_BUSY_WAIT = 1,  /* 0x1 */
  OMP_SPIN_PAUSE_WAIT = 2, /* 0x10 */
  OMP_SPIN_YIELD_WAIT = 4, /* 0x100 */
  OMP_SUSPEND_WAIT = 8,    /* 0x1000 */
  OMP_TERMINATE = 16, /* 0x10000 */

  OMP_ACTIVE_WAIT = OMP_SPIN_PAUSE_WAIT,
  OMP_PASSIVE_WAIT = OMP_SUSPEND_WAIT;
} omp_wait_policy_t; 

int omp_get_num_threads_runtime(omp_wait_policy_t state);

void omp_set_wait_policy(omp_wait_policy_t wait_policy);
int omp_get_wait_policy(void);

int omp_quiesce(omp_wait_policy_t state);

typedef void * omp_thread_t;
int omp_thread_create (omp_thread_t * th, int place,  
   void *(*start_routine)(void *), void *arg, void * new_stack);
void omp_thread_exit(void *value_ptr);
int omp_thread_join(omp_thread_t thread, void **value_ptr);

\end{lstlisting}
The {\sf omp\_wait\_policy\_t} enum defines the valid thread waiting policies that can be passed to the 
related runtime routines. The value for {\sf OMP\_ACTIVE\_WAIT} and {\sf OMP\_PASSIVE\_WAIT} could be defined
in the standard. It is also possible that the standard does not define the five specific policies, and let 
the implementers specify the meaning of {\sf ACTIVE} or {\sf PASSIVE} policies in their implementation. The use of the binary
position bit (0x1, 0x10, etc) as values allows for setting multiple wait policies for a thread such that the thread can automatically change
its waiting behavior according to the needs of the application. 
%to be defined by the
%implementers who will  


%We use those state as the waiting policy that a user would want the runtime threads to be in and the 
\subsection{The {\sf omp\_get\_num\_threads\_runtime} Runtime Routine}
This routines return the number of runtime threads that are under the specified policy. The binding thread set 
of the function is the team threads when being called inside a {\sf parallel} region, and all the threads in the current 
contention group when being called in the sequential region. The information provided by calls to this routines can be used 
by users to make resource management decision when oversubscription become an issue in a program. 

\subsection{The {\sf omp\_set\_wait\_policy} and {\sf omp\_get\_wait\_policy} Runtime Routines}
The {\sf omp\_set\_wait\_policy} runtime setter routine sets wait policy of binding thread(s). 
%It is important to note that the call to this routine impacts differently for 
When being called inside a {\sf parallel} region, the routine sets the wait policy of the calling thread. 
%the master thread will make changes of the wait policy for all the team threads. 
When being called in a sequential region, the routine sets the wait policy for all the 
 threads of the binding contention group. The {\sf omp\_get\_wait\_policy} routine returns the wait policy 
of the binding thread if it is being called inside a {\sf parallel} region. If being called in a sequential region, 
this getter routine returns the wait policy of the contention group if the policy is set before by the setter. 
If no wait policy has been set for the contention group by the setter, the getter routine returns the wait policies 
of all the threads as a combined integer. For example, the return value of 0x1011 indicates that {\sf OMP\_SUSPEND\_WAIT}, 
{\sf OMP\_SPIN\_PAUSE\_WAIT} and {\sf OMP\_SPIN\_BUSY\_WAIT} policies have been set for the threads of the contention group. The
difference of the binding thread set according to where the setter is called (a {\sf parallel} region or sequential region) 
allows users to set different policies of the selected threads in a contention group. 
For example, the {\sf omp\_set\_wait\_policy(OMP\_PASSIVE\_WAIT)} 
call in the sequential region followed by the {\sf omp\_set\_wait\_policy(OMP\_ACTIVE\_WAIT)}  
call inside a {\sf parallel} region enables those threads that are not part of the {\sf parallel} region to be {\sf PASSIVE} 
waiting while other threads to be {\sf ACTIVE} waiting. 
%The valid arguments for this call 
%include {\sf omp\_thread\_state\_SPIN}, {\sf omp\_thread\_state\_YIELD}, 
%and {\sf omp\_thread\_state\_SLEEP}. The value of  {\sf OMP\_ACTIVE\_WAIT} and 
%{\sf OMP\_PASSIVE\_WAIT} could be implementation or language defined. 
The setter call makes changes of the wait policy to individual threads, thus overriding the default 
setting by the {\sf wait-policy-var} ICV and {\sf OMP\_WAIT\_POLICY} variable. 

The {\sf omp\_set\_wait\_policy} routine can be used for addressing both active and passive oversubscription depending on
the location of the call to this routine. Similar routines have been provided in compilers from IBM, Cray and 
Oracle~\cite{ibmwait,craywait,oraclewait}.
There are also different variants of this features depending how much details users can configure
the wait policy. For example, Oracle OpenMP runtime allows users to set policies for specific execution point, e.g, at OpenMP 
barrier or after a {\sf parallel} region. 

\subsection{The {\sf omp\_quiesce} Runtime Routine}
The {\sf omp\_quiesce} routine quiesces all OpenMP threads of the runtime according to 
specified threading behavior by the argument, which could be either {\sf OMP\_SUSPEND\_WAIT} or {\sf OMP\_TERMINATE}. 
Thus quiescence involves termination of threads or otherwise inactivating them. 
The binding thread set include all the threads of the runtime instance. 
%SLEEP or KILL. 
The routine returns zero if quiescence has been achieved, otherwise it returns a non-zero error code.

%The two APIs allow a program to dynamically change the behavior of waiting threads or even shutdown the runtime, thus addressing the passive
%oversubscription issue. 


\subsection{The {\sf omp\_thread\_create/exit/join} Runtime Routines}

The {\sf omp\_thread\_create/exit/join} APIs are introduced for users to create OpenMP threads similarly as the way of creating
PThreads. Those threads however are tracked by the OpenMP runtime, though they do not belong to any thread team. 
The {\sf place} parameter is used for specifying the place where the thread should be created from.  
By using those APIs, an OpenMP thread can be created as regular thread without using OpenMP {\sf parallel} region. 
Those threads can be used to form another parallel runtime for other programming
models. 

%, but also being tracked by the OpenMP runtime, but not belong to any thread team. 


\REM{
with one of the thread state. This will allow programmers to explicitly change the policy at various 
points during a program's execution. An efficient implementation may use atomic write to the 
global ICV and all threads will react accordingly at some later point of the execution after the 
ICV is set. So the effects may be delayed. 
The {\sf omp\_set\_wait\_policy} should only make effects to threads created from the current root thread 
of the runtime when the parameter is one of the three:
{\sf omp\_thread\_state\_WAIT} which corresponds to the {\sf ACTIVE} wait policy, 
{\sf omp\_thread\_state\_YIELD} which corresponds to the {\sf PASSIVE} wait policy, or
{\sf omp\_thread\_state\_SLEEP}. 
%The {\sf ACTIVE} for {\sf OMP\_WAIT\_POLICY} environment variable is the same as 
%the {\sf omp\_thread\_state\_WAIT}, and the {\sf PASSIVE} is the same as the {\sf omp\_thread\_state\_YIELD}.



%, for processing tasks such as message passing that are not computational, or for receiving
%help from user threads to do OpenMP work. We also observed that a highly-interoperable OpenMP proposal is 
%complex for both the usage and implementation of those features. It introduces
%overheads that may not be necessary for a program that does not need to interoperate in that degree of interoperability. 
Thus we categorize interoperability functionalities into the following multiple levels: 
\begin{itemize}
	\item {\bf Level 0, OMP\_INTEROP\_NONE}: No interoperability. The OpenMP runtime does not provide mechanism to interoperate with others.
	\item {\bf Level 1, OMP\_INTEROP\_INFORM}, Informational. Constructs for providing information for others about the internal status of the thread pool, thread affinity info, etc. 
	\item {\bf Level 2, OMP\_INTEROP\_SELF}: Self adjusting threading behavior. Constructs for
		externals to use to adjust its internal threading and affinity behaviors.
	\item {\bf Level 3, OMP\_INTEROP\_CONTRIBUTE}: Contributing. Constructs for externals to use to acquire OpenMP 
		threads or places for doing user-specific tasks that are not part of the OpenMP. It also includes constructs for injecting
		a user-specific task into the runtime. 
	\item {\bf Level 4, OMP\_INTEROP\_REAP}: Receiving help. Constructs for externals to attach user threads into the runtime.
\end{itemize}

In each level, 
OpenMP constructs (directives, runtime APIs and environment variables) are defined to support the interoperability 
requirements. 
An OpenMP implementation that supports a certain level of interoperability should provide the implementation of all the APIs
from level 0 to that level inclusively. 
An environment variable, {\sf OMP\_INTEROP\_LEVEL}, is defined to set the desired level of 
interoperability for an OpenMP program. The actual level during execution depends on both the value of 
the variable and the level which the implementation supports. 
The ``{\sf int omp\_get\_interop\_level()}" procedure should be provided for querying the current level. % being supported by an OpenMP runtime. 
%An OpenMP implementation supports the desired level of interoperability and should 

\subsection{Level 0, OMP\_INTEROP\_NONE}
In this level, an OpenMP runtime should be independent from others, even when there are multiple instances of the same runtime library. 
%An OpenMP runtime instance should be created for each user thread that launch 
%into OpenMP functions. 
The thread behavior, e.g. wait policy, thread-limit, dynamic cannot be changed after the runtime started.
The runtime takes the values of those variables from environment variables. The implementation supporting 
this level should implement the following  
environment variables and some getter functions. 
\lstset{basicstyle=\sffamily\footnotesize,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

OMP_DYNAMIC                     /* in the standard already */
OMP_WAIT_POLICY                 /* in the standard already */
OMP_THREAD_LIMIT                /* in the standard already */
int omp_get_dynamic(void);      /* in the standard already */
int omp_get_thread_limit(void); /* in the standard already */
int omp_get_wait_policy(void);
int omp_get_num_procs(void);    /* in the standard already */

typedef struct omp_thread omp_thread_t;
omp_thread_t * omp_get_initial_thread();

typedef struct omp_runtime_handle omp_runtime_handle_t;
omp_runtime_handle_t omp_get_runtime_handle();
\end{lstlisting}
The {\sf omp\_get\_wait\_policy} implementation should return the value set by the environment. 
As we mentioned that environment setting impacts all the runtime instances by setting the corresponding
ICVs of each runtime the same values. For helping setting runtime-specific ICVs if a setter is available, a program
can use the {\sf omp\_get\_initial\_thread} and {\sf  omp\_get\_runtime\_handle} to retrieve the handle for the
initial thread and a runtime handle. However, a runtime instance can only set the ICVs for its own. 

\subsection{Level 1, OMP\_INTEROP\_INFORM}
This level defines APIs for users to query the internal status of the runtime, including the size of thread pool, the number of threads
that are busy-waiting, yielding or sleeping. The status of a thread includes RUN, WAIT, YIELD, SLEEP, KILL, and BLOCK. 

\lstset{basicstyle=\sffamily\small,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

typedef enum omp_wait_policy {
  omp_wait_policy_RUN = 0,     /* doing useful work */
  omp_wait_policy_WAIT = 1,    /* busy waiting for work */
  omp_wait_policy_YIELD = 2,   /* yield the CPU */
  omp_wait_policy_SLEEP = 3,   /* sleeping */
  omp_wait_policy_KILL = 4,    /* being killed */
  omp_wait_policy_BLOCK = 5,   /* blocked waiting */
} omp_wait_policy_t; 
int omp_get_num_threads_runtime(omp_wait_policy_t state);
\end{lstlisting}

By using the API, a program would be able to claims or allocate appropriate amount of resources based on how many are occupied by the OpenMP
runtime to avoid active oversubscription. 

\subsection{Level 2, OMP\_INTEROP\_SELF} 
In this level, APIs are defined for adjusting the runtime behavior of the runtime, including the wait policy, dynamic feature, etc.

\begin{lstlisting}[frame=single]
void omp_set_dynamic(int dyn_threads); /*in standard already*/
void omp_set_wait_policy(omp_wait_policy_t wait_policy);
int omp_quiesce(omp_wait_policy_t state);
\end{lstlisting}
The {\sf omp\_set\_dynamic} is already in the standard. 

The {\sf omp\_quiesce} routine quiesces all OpenMP threads of the runtime according to specified threading behavior by the parameter. The
parameter could be either WAIT, YIELD, SLEEP, or KILL. Quiescence may involve termination
 of threads or otherwise inactivating them. The routine returns zero if quiescence has been achieved, otherwise it returns a non-zero error code.

The two APIs allow a program to dynamically change the behavior of waiting threads or even shutdown the runtime, thus addressing the passive
oversubscription issue. 


\subsection{Level 3, OMP\_INTEROP\_CONTRIBUTE}
The APIs in this level mean to contribute the resources owned by an OpenMP runtime to externals. 
% for operations that are not easy to describe using OpenMP directives.  

\lstset{basicstyle=\sffamily\small,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

int omp_thread_create (omp_thread_t * th, int place,  
   void *(*start_routine)(void *), void *arg, void * new_stack);
void omp_thread_exit(void *value_ptr);
int omp_thread_join(omp_thread_t thread, void **value_ptr);

typedef struct omp_task omp_task_t;
void omp_task_create(omp_task_t * t, void *(*task_func)(void *), 
  void * task_args, int (*task_test_func)(omp_task_t), 
  int *intags, int num_intags, int * outtags, int num_outtags);
\end{lstlisting}
The {\sf omp\_thread\_create/exit/join} APIs are for creating OpenMP threads similarly as user threads such 
as PThreads. The {\sf place} parameter is used for specifying the place where the thread should be created from.  
By using those APIs, an OpenMP thread
can be used as regular thread without using OpenMP parallel region. Those threads can be used to form another parallel runtime for other programming
models, but also being tracked by the OpenMP runtime, but not belong to any thread team. 

The {\sf omp\_task\_create} procedure allows users to inject non-blocking tasks into the OpenMP runtime. A non-blocking task does not occupy
a thread during the execution, it only requires the runtime to launch the task and to periodically query the task internally. The non-blocking
tasks will be part of a {\sf taskgroup}, or joining a {\sf taskwait} or {\sf barrier} synchronization. It can be used with task dependencies by 
passing the tags for in and out dependency. A typical use case for this API is to request OpenMP runtime to launch a non-blocking MPI call by providing the call information and a function pointer for query the completion of this task. Again, runtime only launches the tasks and then periodically
query its status using the provided {\sf task\_test\_func} function pointer parameter of {\sf omp\_thread\_create}.

\subsection{Level 4, OMP\_INTEROP\_REAP} 
The philosophy of this level of interoperability support is to enable an OpenMP runtime to accept offer of threads 
for helping its own execution. This is different than the approach of claiming CPU cores 
for computation using the standard parallel region creation. By allowing program to offer threads to the runtime who needs it, we are able to 
reap the resources for computation, thus reducing the overhead of thread creation and context switching when otherwise 
a thread has to be terminated from
one runtime and then recreated in another runtime in order to use the same core. 
\lstset{basicstyle=\sffamily\small,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

int omp_thread_attach(omp_runtime_handle_t runtime, 
    void * new_stack, int place, int * term_flag);
\end{lstlisting}

The {\sf omp\_thread\_attach} procedure accepts a parameter for specifying a new stack for the thread when it joins the runtime. It also 
allows for specifying a target place the thread should bind to. 
The {\sf term\_flag} 
is used for signaling the runtime that the attached thread should terminate when the variable becomes true. 
The runtime evaluates the {\sf term\_flag} when the thread is not performing OpenMP work. 



There are still some challenges in terms of OpenMP interoperability. 
OpenMP threads that are created by the parallel construct cannot interact with external systems. 
In other words, we are trying to enable the interoperability through flexible communication between OpenMP threads and user threads. 
However, the main goal of this work is to achieve a high level of resource utilization. So, it would be better if OpenMP threads can interact and communicate with user threads. To achieve this goal, we implement four new functions as follows:
\begin{enumerate}
	\item int omp{\_}set{\_}wait{\_}policy(ACTIVE \textbar PASSIVE): 
	set the waiting thread behavior. The function returns the current wait{\_}policy, which could be different from intention of the call depending on the decision made by the runtime. If the value is PASSIVE, waiting threads should not consume CPU power while waiting; while the value is ACTIVE specifies that they should.
	\item int omp{\_}thread{\_}create( ): 
	to give the user the ability to create an OpenMP thread without using \#pragma omp parallel directive, and lets it be a user thread similar to pthread.
	\item int omp{\_}quiesce( ): 
	to shutdown or unload the OpenMP runtime library.
\end{enumerate}
}
