%Parallel programming models such as 
OpenMP has been evolved to be a comprehensive programming model for parallel and heterogeneous computing nodes by including 
data parallelism, task parallelism, offloading execution model, etc. in one unified model. 
The runtime systems are becoming more complicated than before to support those language features.
A typical OpenMP runtime maintains an internal thread pool to keep tracking those threads allocated by the runtime even they are not  
doing any OpenMP operation during the sequential execution of the program. 
A thread in the thread pool could be in either busy-waiting state which occupies a CPU core, or in the kernel
scheduling queue after a yield system call (e.g. {\em sched\_yield} in Linux), or could be put to sleep. 
Some OpenMP runtime also maintains
internal hot teams in which threads are busy-waiting for work even if the program is in the sequential stage. 
So an OpenMP program could 
consumes cycles of multiple CPU cores even if it is in sequential execution stage.

This interoperability proposal attemps to address the oversubscription (both CPU and memory) challenges by providing more information or control
to users for the threads in the runtime. The proposal also provides mechanism for an OpenMP runtime to interact with externals, including 
contributing OpenMP threads for another parallel runtime, for processing tasks such as message passing that are not computational, or for receiving
help from user threads to do OpenMP work. We also observed that a highly-interoperable OpenMP proposal is 
complex for both the usage and implementation of those features. It introduces
overheads that may not be necessnary for a program that does not need to interoperate in that degree of interoperability. 
Thus our principle to support OpenMP interoperability is by 
categorizing interoperability functionalities into multiple levels. In each level, 
OpenMP constructs (directives, runtime APIs and environment variables) are defined to support the interoperability 
requirements. 
\begin{itemize}
	\item {\bf Level 0, OMP\_INTEROP\_NONE}: No interoperability. The OpenMP runtime do not provide mechanism to interoperate with others.
	\item {\bf Level 1, OMP\_INTEROP\_INFORM}, Informational. Constructs for providing information for others about the internal status of the thread pool, memory affinity info, etc. 
	\item {\bf Level 2, OMP\_INTEROP\_SELF}: Self adjusting threading behavior. Constructs for
		externals to use to adjust its internal threading and affinity behaviors.
	\item {\bf Level 3, OMP\_INTEROP\_CONTRIBUTE}: Contributing. Constructs for externals to use to acquire OpenMP 
		threads or place for doing user-specific tasks that are not part of the OpenMP. It also includes constructs for injecting
		a user-specific task into the runtime. 
	\item {\bf Level 4, OMP\_INTEROP\_REAP}: Receiving help. Consturcts for externals to attach user threads or memory affinity into the runtime.
\end{itemize}

An OpenMP implementation that supports a certain level of interoperability should provide the implementation of all the APIs
from level 0 to that level inclusively. 
An environment variable, {\sf OMP\_INTEROP\_LEVEL}, is defined to set the desired level of 
interoperability for an OpenMP program. The actual level during execution depends on both the value of 
the variable and the level which the implementation supports. 
The ``{\sf int omp\_get\_interop\_level()}" procedure should be provided for querying the current level. % being supported by an OpenMP runtime. 
%An OpenMP implementation supports the desired level of interoperability and should 

\subsection{Level 0, OMP\_INTEROP\_NONE}
In this level, an OpenMP runtime should be independent from others, even with another instance of the same library. 
%An OpenMP runtime instance should be created for each user thread that launch 
%into OpenMP functions. 
The thread behavior, e.g. wait policy, thread-limit, dynamic cannot be changed after the runtime started.
The runtime takes the values of those variables from environment variables. The implementation supporting 
this level should implement the following  
environment variables and some getter functions. 
\lstset{basicstyle=\sffamily\footnotesize,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

OMP_DYNAMIC                     /* in the standard already */
OMP_WAIT_POLICY                 /* in the standard already */
OMP_THREAD_LIMIT                /* in the standard already */
int omp_get_dynamic(void);      /* in the standard already */
int omp_get_thread_limit(void); /* in the standard already */
int omp_get_wait_policy(void);
int omp_get_num_procs(void);    /* in the standard already */

typedef struct omp_thread omp_thread_t;
omp_thread_t * omp_get_initial_thread();

typedef struct omp_runtime_handle omp_runtime_handle_t;
omp_runtime_handle_t omp_get_runtime_handle();
\end{lstlisting}
The {\sf omp\_get\_wait\_policy} implementation should return the value set by the environment. 
As we mentioned that environment setting impacts all the runtime instances by setting the corresponding
ICVs of each runtime the same values. For helping setting runtime-specific ICVs if a setter is available, a program
can use the {\sf omp\_get\_initial\_thread} and {\sf  omp\_get\_runtime\_handle} to retrieve the handle for the
initial thread and a runtime handle. However, a runtime instance can only set the ICVs for its own. 

\subsection{Level 1, OMP\_INTEROP\_INFORM}
This level defines APIs for users to query the internal status of the runtime, including the size of thread pool, the number of threads
that are busy-waiting, yielding or sleeping. The status of a thread includes RUN, WAIT, YIELD, SLEEP, KILL, and BLOCK. 

\lstset{basicstyle=\sffamily\small,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

typedef enum omp_thread_state {
  omp_thread_state_RUN = 0,     /* doing useful work */
  omp_thread_state_WAIT = 1,    /* busy waiting for work */
  omp_thread_state_YIELD = 2,   /* yield the CPU */
  omp_thread_state_SLEEP = 3,   /* sleeping */
  omp_thread_state_KILL = 4,    /* being killed */
  omp_thread_state_BLOCK = 5,   /* blocked waiting */
} omp_thread_state_t; 
int omp_get_num_threads_runtime(omp_thread_state_t state);
\end{lstlisting}

By using the API, a program would be able to claims or allocate appropriate amount of resources based on how many are occupied by the OpenMP
runtime to avoid active oversubscriptions. 

\subsection{Level 2, OMP\_INTEROP\_SELF} 
In this level, APIs are defined for adjusting the runtime behavior of the runtime, including the wait policy, dynamic feature, etc.

\begin{lstlisting}[frame=single]
void omp_set_dynamic(int dynamic_threads); /* in the standard already */
void omp_set_wait_policy(omp_thread_state_t wait_policy);
int omp_quiesce(omp_thread_state_t state);
\end{lstlisting}
The {\sf omp\_set\_dynamic} is alreay in the standard. The {\sf void omp\_set\_wait\_policy(omp\_thread\_state\_t)} API
sets the the wait-policy-var
ICV with one of the thread state. This will allow programmer to explicitly change the policy at various 
points during a program's execution. An efficient implementation may use atomic write to the 
global ICV and all threads will react accordingly at some later point of the exectution after the 
ICV is set. So the effects may be delayed. 
The {\sf omp\_set\_wait\_policy} should only make effects to threads created from the current root thread 
of the runtime when the parameter is one of the three:
{\sf omp\_thread\_state\_WAIT}, which cooresponds to the {\sf ACTIVE} wait policy, 
{\sf omp\_thread\_state\_YIELD} which cooresonds to the {\sf PASSIVE} wait policy, or
{\sf omp\_thread\_state\_SLEEP}. 
%The {\sf ACTIVE} for {\sf OMP\_WAIT\_POLICY} environment variable is the same as 
%the {\sf omp\_thread\_state\_WAIT}, and the {\sf PASSIVE} is the same as the {\sf omp\_thread\_state\_YIELD}.
Compilers from IBM, Cray and Oracle have provide this feature~\cite{ibmwait,craywait,oraclewait}.
There are also different variants of this features depending how much details users can configure
the wait policy.

The {\sf omp\_quiesce} routine quiesces all OpenMP threads of the runtime according to specified threading behavior by the parameter. The
parameter could be either WAIT, YIELD, SLEEP, or KILL. Quiescence may involve termination
 of threads or otherwise inactivating them. The routine returns zero if quiescence has been achieved, otherwise it returns a non-zero error code.

The two APIs allow a program to dynamically change the behavior of waiting threads or even shutdown the runtime, thus addressing the passive
oversubscription issue. 
\subsection{Level 3, OMP\_INTEROP\_CONTRIBUTE}
The APIs in this level mean to contribute the resources owned by the OpenMP for operations that are not easy to perform using OpenMP directives.  

\lstset{basicstyle=\sffamily\small,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

int omp_thread_create (omp_thread_t * th, int place,  
   void *(*start_routine)(void *), void *arg, void * new_stack);
void omp_thread_exit(void *value_ptr);
int omp_thread_join(omp_thread_t thread, void **value_ptr);

typedef struct omp_task omp_task_t;
void omp_task_create(omp_task_t * t, void *(*task_func)(void *), 
  void * task_args, int (*task_test_func)(omp_task_t), 
  int *intags, int num_intags, int * outtags, int num_outtags);
\end{lstlisting}
The {\sf omp\_thread\_create/exit/join} APIs are for creating OpenMP threads similarly as user threads such 
as PThreads. The {\sf place} parameter is used for specifying the place where the thread should be created from.  
By using those APIs, an OpenMP thread
can be used as regular thread without using OpenMP parallel region. Those threads can be used to form another parallel runtime for other programming
models, but also being tracked by the OpenMP runtime. 

The {\sf omp\_task\_create} procedure allows users to inject non-blocking tasks into the OpenMP runtime. A non-blocking task does not occupy
a thread during the execution, it only requires the runtime to launch the task and to periodically query the task internally. The non-blocking
tasks will be part of a {\sf taskgroup}, or joining a {\sf taskwait} or {\sf barrier} synchronization. It can be used with task dependencies by 
passing the tags for in and out dependency. A typicall use case for this API is to request OpenMP runtime to launch a non-blocking MPI call by providing the call information and a function pointer for query the completion of this task. Again, runtime only launchs the tasks and then periodically
query its status using the provided {\sf task\_test\_func}.

\subsection{Level 4, OMP\_INTEROP\_REAP} 
The philosophy of this level of interoperability support is to enable an OpenMP runtime to accept offer of threads 
for helping the OpenMP execution. This is different than the approach of claiming CPU cores 
for computation using the standard parallel region creation. By allowing program to offer threads to the runtime who needs it, we are able to 
reap the resources for computation, thus reducing the overhead of thread creation and context switching when otherwise 
a thread has to be terminated from
one runtime and then recreated in another runtime in order to use the same core. 
\lstset{basicstyle=\sffamily\small,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

int omp_thread_attach(omp_runtime_handle_t runtime, 
    void * new_stack, int place, int * term_flag);
\end{lstlisting}

The {\sf omp\_thread\_attach} procedure accepts a parameter for specifying a new stack for the thread when it joins the runtime. It also 
allows for specifying a target place the thread should bind to. 
The {\sf term\_flag} 
is used for signalling the runtime that the attached thread should terminate when the variable becomes true. 
The runtime evaluates the {\sf term\_flag} when the thread is not performing OpenMP work. 



\REM{
There are still some challenges in terms of OpenMP interoperability. 
OpenMP threads that are created by the parallel construct cannot interact with external systems. 
In other words, we are trying to enable the interoperability through flexible communication between OpenMP threads and user threads. 
However, the main goal of this work is to achieve a high level of resource utilization. So, it would be better if OpenMP threads can interact and communicate with user threads. To achieve this goal, we implement four new functions as follows:
\begin{enumerate}
	\item int omp{\_}set{\_}wait{\_}policy(ACTIVE \textbar PASSIVE): 
	set the waiting thread behavior. The function returns the current wait{\_}policy, which could be different from intention of the call depending on the decision made by the runtime. If the value is PASSIVE, waiting threads should not consume CPU power while waiting; while the value is ACTIVE specifies that they should.
	\item int omp{\_}thread{\_}create( ): 
	to give the user the ability to create an OpenMP thread without using \#pragma omp parallel directive, and lets it be a user thread similar to pthread.
	\item int ompe{\_}quiesce( ): 
	to shutdown or unload the OpenMP runtime library.
\end{enumerate}
}
