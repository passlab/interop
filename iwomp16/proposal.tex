OpenMP has been evolved to be a unified programming model for 
parallel and heterogeneous computing nodes by including fork-join execution model, 
data parallelism (worksharing), task parallelism, offloading execution model, etc.. 
The runtime systems are becoming more complicated than before to support those language features.
A typical OpenMP runtime maintains 
an internal thread pool to keep track of the native threads created by the runtime even they are not  
doing any OpenMP operation during the sequential execution of the program. 
In the fork-join OpenMP execution model, a native thread in the thread pool 
is summoned to participate in an OpenMP team for computation upon the fork of the {\sf parallel} region. 
The native thread returns back to the thread pool when a parallel 
region is finished at the join barrier. While in the 
thread pool, a native thread blocks in a fork barrier. The blocking mechaims could be  
either busy-waiting which occupies a CPU core, or in the kernel
scheduling queue after a yield system call (e.g. {\em sched\_yield} in Linux), or could be put to sleep. 
Some OpenMP runtime also maintains
internal hot teams in which threads are busy-waiting for work even if the program is in the sequential stage. 
So an OpenMP program could consumes cycles of multiple CPU cores even if it is in sequential execution stage. In summary, an OpenMP runtime 
thread could be in one of the following states while not participating in OpenMP computations.  
\begin{itemize}
	\item {\bf SPIN-WAIT}: The native thread spins waiting in the barrier call. 
%		It is released from the barrier to participate in a team for computation by the runtime. 
		SPIN waiting consumes CPU cycles.
	\item {\bf YIELD}: The native thread relinquishs the CPU by kernel system call (e.g. {\em sched\_yield}) 
		and is moved to the end of the kernel scheduling queue for its static priority. A thread in this 
		stage can only be released to the OpenMP runtime by the kernel. 
		% This is a kernel state while the runtime consider this as block system call. 
	\item {\bf YIELD-SPIN}: The thread alternates the YIELD and SPIN cycles such that the thread can 
		periodically query whether it is being called to join a team. The YIELD-SPIN state is actually the 
		state the OpenMP runtime uses to manage the resources. 
	\item {\bf SLEEP}: The thread is putting to SLEEP state such that it is completely suspended. A sleeping
		thread can only be resumed by other threads or being timed out. 
\end{itemize}
It is also often that an OpenMP program explicitly create native threads, e.g. PThreads, and each native thread has
its own OpenMP {\sf parallel} region. 
In such hybrid user-level native thread/OpenMP program, e.g. 
a runtime may form an internal decendant hierarchy for the native threads created by users and
those by the OpenMP runtime. Borrowing the terms from Intel OpenMP runtime implementation, we refer to 
the native threads created by users as root threads. 
In the most recent OpenMP standard, a root thread forms a contention group and we thus 
consider all the decedant threads are members of the contention group. 


This interoperability proposal is an effort from OpenMP interoperability language subcommittee for addressing
the oversubscription challenges of OpenMP programs when being executed with other threading library. 
Our approach provides runtime routines to explose certain functionalities of the runtime systems for users to 
intrusively adjust the runtime behavior. 
The solution includes runtime API for providing more information or control to users 
for the threads in the runtime, 
%The proposal also provides mechanism for an OpenMP runtime to interact with externals,
and mechanisms for 
contributing OpenMP threads for another parallel runtime. 
%Parallel programming models such as 
The proposal introduces the following definition of data types and runtime routines. 

\lstset{basicstyle=\sffamily\small,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

typedef enum omp_thread_state {
  omp_thread_state_RUN = 0,     /* doing users' work */
  omp_thread_state_SPIN = 1,    /* busy waiting for work */
  omp_thread_state_YIELD = 2,   /* yield or yield-spin */
  omp_thread_state_SLEEP = 3,   /* sleeping */
  omp_thread_state_KILL = 4,    /* being killed */

  OMP_ACTIVE_WAIT = omp_thread_state_SPIN,
  OMP_PASSIVE_WAIT = omp_thread_state_SLEEP;
} omp_thread_state_t; 

int omp_get_num_threads_runtime(omp_thread_state_t state);

void omp_set_wait_policy(omp_thread_state_t wait_policy);
int omp_get_wait_policy(void);

int omp_quiesce(omp_thread_state_t state);

typedef void * omp_thread_t;
int omp_thread_create (omp_thread_t * th, int place,  
   void *(*start_routine)(void *), void *arg, void * new_stack);
void omp_thread_exit(void *value_ptr);
int omp_thread_join(omp_thread_t thread, void **value_ptr);

\end{lstlisting}

We use those state as the waiting policy that a user would want the runtime threads to be in and the {\sf omp\_get\_num\_threads\_runtime} API returns the number of runtime threads in the specified state.

\subsection{The {\sf omp\_set\_wait\_policy} and {\sf omp\_get\_wait\_policy} Runtime Routines}
The {\sf void omp\_set\_wait\_policy (omp\_thread\_state\_t)} runtime routine sets wait policy of certain 
native threads. It is important to note that the call to this routine impacts differently for 
whether it is called inside a {\sf parallel} region or in a sequential region. 
When being called inside a parallel region, the master thread will make changes of the wait policy for all the team 
threads. When being called in a sequential region, the root thread will make chanages for all child threads of 
the contention group led by the root thread. The valid arguments for this call 
include {\sf omp\_thread\_state\_SPIN}, {\sf omp\_thread\_state\_YIELD}, 
and {\sf omp\_thread\_state\_SLEEP}. The value of  {\sf OMP\_ACTIVE\_WAIT} and 
{\sf OMP\_PASSIVE\_WAIT} could be implementation or language defined. The call makes changes of the wait
policy to each invidual thread, thus thread waiting behavior overrides the default 
setting by the wait-policy-var ICV and OMP\_WAIT\_POLICY environment variables. 
Compilers from IBM, Cray and Oracle have provide similar feature~\cite{ibmwait,craywait,oraclewait}.
There are also different variants of this features depending how much details users can configure
the wait policy.

\subsection{The {\sf omp\_quiesce} Runtime Routine}
The {\sf omp\_quiesce} routine quiesces all OpenMP threads of the runtime according to 
specified threading behavior by the parameter, which could be SLEEP or KILL. 
Quiescence may involve termination of threads or otherwise inactivating them. The routine returns zero if quiescence has been achieved, otherwise it returns a non-zero error code.

The two APIs allow a program to dynamically change the behavior of waiting threads or even shutdown the runtime, thus addressing the passive
oversubscription issue. 


\subsection{The {\sf omp\_thread\_create/exit/join} Runtime Routines}

The {\sf omp\_thread\_create/exit/join} APIs are for creating OpenMP threads similarly as user threads such 
as PThreads. The {\sf place} parameter is used for specifying the place where the thread should be created from.  
By using those APIs, an OpenMP thread
can be used as regular thread without using OpenMP parallel region. Those threads can be used to form another parallel runtime for other programming
models, but also being tracked by the OpenMP runtime, but not belong to any thread team. 


\REM{
with one of the thread state. This will allow programmers to explicitly change the policy at various 
points during a program's execution. An efficient implementation may use atomic write to the 
global ICV and all threads will react accordingly at some later point of the execution after the 
ICV is set. So the effects may be delayed. 
The {\sf omp\_set\_wait\_policy} should only make effects to threads created from the current root thread 
of the runtime when the parameter is one of the three:
{\sf omp\_thread\_state\_WAIT} which corresponds to the {\sf ACTIVE} wait policy, 
{\sf omp\_thread\_state\_YIELD} which corresponds to the {\sf PASSIVE} wait policy, or
{\sf omp\_thread\_state\_SLEEP}. 
%The {\sf ACTIVE} for {\sf OMP\_WAIT\_POLICY} environment variable is the same as 
%the {\sf omp\_thread\_state\_WAIT}, and the {\sf PASSIVE} is the same as the {\sf omp\_thread\_state\_YIELD}.



%, for processing tasks such as message passing that are not computational, or for receiving
%help from user threads to do OpenMP work. We also observed that a highly-interoperable OpenMP proposal is 
%complex for both the usage and implementation of those features. It introduces
%overheads that may not be necessary for a program that does not need to interoperate in that degree of interoperability. 
Thus we categorize interoperability functionalities into the following multiple levels: 
\begin{itemize}
	\item {\bf Level 0, OMP\_INTEROP\_NONE}: No interoperability. The OpenMP runtime does not provide mechanism to interoperate with others.
	\item {\bf Level 1, OMP\_INTEROP\_INFORM}, Informational. Constructs for providing information for others about the internal status of the thread pool, thread affinity info, etc. 
	\item {\bf Level 2, OMP\_INTEROP\_SELF}: Self adjusting threading behavior. Constructs for
		externals to use to adjust its internal threading and affinity behaviors.
	\item {\bf Level 3, OMP\_INTEROP\_CONTRIBUTE}: Contributing. Constructs for externals to use to acquire OpenMP 
		threads or places for doing user-specific tasks that are not part of the OpenMP. It also includes constructs for injecting
		a user-specific task into the runtime. 
	\item {\bf Level 4, OMP\_INTEROP\_REAP}: Receiving help. Constructs for externals to attach user threads into the runtime.
\end{itemize}

In each level, 
OpenMP constructs (directives, runtime APIs and environment variables) are defined to support the interoperability 
requirements. 
An OpenMP implementation that supports a certain level of interoperability should provide the implementation of all the APIs
from level 0 to that level inclusively. 
An environment variable, {\sf OMP\_INTEROP\_LEVEL}, is defined to set the desired level of 
interoperability for an OpenMP program. The actual level during execution depends on both the value of 
the variable and the level which the implementation supports. 
The ``{\sf int omp\_get\_interop\_level()}" procedure should be provided for querying the current level. % being supported by an OpenMP runtime. 
%An OpenMP implementation supports the desired level of interoperability and should 

\subsection{Level 0, OMP\_INTEROP\_NONE}
In this level, an OpenMP runtime should be independent from others, even when there are multiple instances of the same runtime library. 
%An OpenMP runtime instance should be created for each user thread that launch 
%into OpenMP functions. 
The thread behavior, e.g. wait policy, thread-limit, dynamic cannot be changed after the runtime started.
The runtime takes the values of those variables from environment variables. The implementation supporting 
this level should implement the following  
environment variables and some getter functions. 
\lstset{basicstyle=\sffamily\footnotesize,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

OMP_DYNAMIC                     /* in the standard already */
OMP_WAIT_POLICY                 /* in the standard already */
OMP_THREAD_LIMIT                /* in the standard already */
int omp_get_dynamic(void);      /* in the standard already */
int omp_get_thread_limit(void); /* in the standard already */
int omp_get_wait_policy(void);
int omp_get_num_procs(void);    /* in the standard already */

typedef struct omp_thread omp_thread_t;
omp_thread_t * omp_get_initial_thread();

typedef struct omp_runtime_handle omp_runtime_handle_t;
omp_runtime_handle_t omp_get_runtime_handle();
\end{lstlisting}
The {\sf omp\_get\_wait\_policy} implementation should return the value set by the environment. 
As we mentioned that environment setting impacts all the runtime instances by setting the corresponding
ICVs of each runtime the same values. For helping setting runtime-specific ICVs if a setter is available, a program
can use the {\sf omp\_get\_initial\_thread} and {\sf  omp\_get\_runtime\_handle} to retrieve the handle for the
initial thread and a runtime handle. However, a runtime instance can only set the ICVs for its own. 

\subsection{Level 1, OMP\_INTEROP\_INFORM}
This level defines APIs for users to query the internal status of the runtime, including the size of thread pool, the number of threads
that are busy-waiting, yielding or sleeping. The status of a thread includes RUN, WAIT, YIELD, SLEEP, KILL, and BLOCK. 

\lstset{basicstyle=\sffamily\small,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

typedef enum omp_thread_state {
  omp_thread_state_RUN = 0,     /* doing useful work */
  omp_thread_state_WAIT = 1,    /* busy waiting for work */
  omp_thread_state_YIELD = 2,   /* yield the CPU */
  omp_thread_state_SLEEP = 3,   /* sleeping */
  omp_thread_state_KILL = 4,    /* being killed */
  omp_thread_state_BLOCK = 5,   /* blocked waiting */
} omp_thread_state_t; 
int omp_get_num_threads_runtime(omp_thread_state_t state);
\end{lstlisting}

By using the API, a program would be able to claims or allocate appropriate amount of resources based on how many are occupied by the OpenMP
runtime to avoid active oversubscription. 

\subsection{Level 2, OMP\_INTEROP\_SELF} 
In this level, APIs are defined for adjusting the runtime behavior of the runtime, including the wait policy, dynamic feature, etc.

\begin{lstlisting}[frame=single]
void omp_set_dynamic(int dyn_threads); /*in standard already*/
void omp_set_wait_policy(omp_thread_state_t wait_policy);
int omp_quiesce(omp_thread_state_t state);
\end{lstlisting}
The {\sf omp\_set\_dynamic} is already in the standard. 

The {\sf omp\_quiesce} routine quiesces all OpenMP threads of the runtime according to specified threading behavior by the parameter. The
parameter could be either WAIT, YIELD, SLEEP, or KILL. Quiescence may involve termination
 of threads or otherwise inactivating them. The routine returns zero if quiescence has been achieved, otherwise it returns a non-zero error code.

The two APIs allow a program to dynamically change the behavior of waiting threads or even shutdown the runtime, thus addressing the passive
oversubscription issue. 


\subsection{Level 3, OMP\_INTEROP\_CONTRIBUTE}
The APIs in this level mean to contribute the resources owned by an OpenMP runtime to externals. 
% for operations that are not easy to describe using OpenMP directives.  

\lstset{basicstyle=\sffamily\small,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

int omp_thread_create (omp_thread_t * th, int place,  
   void *(*start_routine)(void *), void *arg, void * new_stack);
void omp_thread_exit(void *value_ptr);
int omp_thread_join(omp_thread_t thread, void **value_ptr);

typedef struct omp_task omp_task_t;
void omp_task_create(omp_task_t * t, void *(*task_func)(void *), 
  void * task_args, int (*task_test_func)(omp_task_t), 
  int *intags, int num_intags, int * outtags, int num_outtags);
\end{lstlisting}
The {\sf omp\_thread\_create/exit/join} APIs are for creating OpenMP threads similarly as user threads such 
as PThreads. The {\sf place} parameter is used for specifying the place where the thread should be created from.  
By using those APIs, an OpenMP thread
can be used as regular thread without using OpenMP parallel region. Those threads can be used to form another parallel runtime for other programming
models, but also being tracked by the OpenMP runtime, but not belong to any thread team. 

The {\sf omp\_task\_create} procedure allows users to inject non-blocking tasks into the OpenMP runtime. A non-blocking task does not occupy
a thread during the execution, it only requires the runtime to launch the task and to periodically query the task internally. The non-blocking
tasks will be part of a {\sf taskgroup}, or joining a {\sf taskwait} or {\sf barrier} synchronization. It can be used with task dependencies by 
passing the tags for in and out dependency. A typical use case for this API is to request OpenMP runtime to launch a non-blocking MPI call by providing the call information and a function pointer for query the completion of this task. Again, runtime only launches the tasks and then periodically
query its status using the provided {\sf task\_test\_func} function pointer parameter of {\sf omp\_thread\_create}.

\subsection{Level 4, OMP\_INTEROP\_REAP} 
The philosophy of this level of interoperability support is to enable an OpenMP runtime to accept offer of threads 
for helping its own execution. This is different than the approach of claiming CPU cores 
for computation using the standard parallel region creation. By allowing program to offer threads to the runtime who needs it, we are able to 
reap the resources for computation, thus reducing the overhead of thread creation and context switching when otherwise 
a thread has to be terminated from
one runtime and then recreated in another runtime in order to use the same core. 
\lstset{basicstyle=\sffamily\small,language=c, numbersep=1pt}
\begin{lstlisting}[frame=single]  % Start your code-block

int omp_thread_attach(omp_runtime_handle_t runtime, 
    void * new_stack, int place, int * term_flag);
\end{lstlisting}

The {\sf omp\_thread\_attach} procedure accepts a parameter for specifying a new stack for the thread when it joins the runtime. It also 
allows for specifying a target place the thread should bind to. 
The {\sf term\_flag} 
is used for signaling the runtime that the attached thread should terminate when the variable becomes true. 
The runtime evaluates the {\sf term\_flag} when the thread is not performing OpenMP work. 



There are still some challenges in terms of OpenMP interoperability. 
OpenMP threads that are created by the parallel construct cannot interact with external systems. 
In other words, we are trying to enable the interoperability through flexible communication between OpenMP threads and user threads. 
However, the main goal of this work is to achieve a high level of resource utilization. So, it would be better if OpenMP threads can interact and communicate with user threads. To achieve this goal, we implement four new functions as follows:
\begin{enumerate}
	\item int omp{\_}set{\_}wait{\_}policy(ACTIVE \textbar PASSIVE): 
	set the waiting thread behavior. The function returns the current wait{\_}policy, which could be different from intention of the call depending on the decision made by the runtime. If the value is PASSIVE, waiting threads should not consume CPU power while waiting; while the value is ACTIVE specifies that they should.
	\item int omp{\_}thread{\_}create( ): 
	to give the user the ability to create an OpenMP thread without using \#pragma omp parallel directive, and lets it be a user thread similar to pthread.
	\item int omp{\_}quiesce( ): 
	to shutdown or unload the OpenMP runtime library.
\end{enumerate}
}
